{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import math\n",
    "import os,shutil\n",
    "\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from keras import layers\n",
    "from keras.applications import DenseNet121\n",
    "from keras.callbacks import Callback, ModelCheckpoint\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import cohen_kappa_score, accuracy_score\n",
    "import scipy\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(2019)\n",
    "tf.set_random_seed(2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3662, 2)\n",
      "(1928, 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_code</th>\n",
       "      <th>diagnosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000c1434d8d7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>001639a390f0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0024cdab0c1e</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>002c21358ce6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>005b95c28852</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id_code  diagnosis\n",
       "0  000c1434d8d7          2\n",
       "1  001639a390f0          4\n",
       "2  0024cdab0c1e          1\n",
       "3  002c21358ce6          0\n",
       "4  005b95c28852          0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv('train.csv')\n",
    "test_df = pd.read_csv('test.csv')\n",
    "print(train_df.shape)\n",
    "print(test_df.shape)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1805\n",
       "2     999\n",
       "1     370\n",
       "4     295\n",
       "3     193\n",
       "Name: diagnosis, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD4CAYAAAAAczaOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAVd0lEQVR4nO3df4xlZ33f8fcnNhDkITaJ6dTxmq6RFiT/SFx2ZFylQTOFwGIQhhbRtVyw+ZGFAmpQkIKdpoVCLVkthgo7MV2wZbs4Hiwc2I1jlzqOVw5SDXipw9qAYQ2L6pW127BmNwMrt2u+/WPOhst6ftwfM3cWP++XdHXPfZ7nnPM9Z+/9zLnnnns3VYUkqQ2/tNYFSJLGx9CXpIYY+pLUEENfkhpi6EtSQ05c6wKWc+qpp9b69euHmvfHP/4xJ5100soWtAKsazDWNRjrGswzsa6dO3f+bVW9YMHOqjqubxs3bqxh3XvvvUPPu5qsazDWNRjrGswzsS7ggVokUz29I0kNMfQlqSGGviQ1xNCXpIYY+pLUEENfkhpi6EtSQwx9SWqIoS9JDTnuf4ZhFLv2HuSyy/9i7Ovdc9Vrx75OSeqHR/qS1BBDX5IasmzoJ7khyf4kD/W0fS7Jg91tT5IHu/b1SQ739H2qZ56NSXYl2Z3kk0myOpskSVpMP+f0bwSuBW4+2lBV//LodJKrgYM94x+tqvMWWM51wO8CXwHuBDYBdw1esiRpWMse6VfVfcCBhfq6o/U3A7cutYwkpwG/UlX3dz/7eTPwhsHLlSSNIvMZvMygZD1wR1Wdc0z7y4GPV9VUz7iHge8Ah4A/qqq/TjIFXFVVr+zG/Tbwwap63SLr2wJsAZicnNw4Ozs7zLax/8BB9h0eataRnHv6yUv2z83NMTExMaZq+mddg7GuwVjXYEapa2ZmZufRXD7WqJdsXszPH+U/Drywqn6YZCPwxSRnD7rQqtoKbAWYmpqq6enpoYq75pZtXL1r/Fel7rlkesn+HTt2MOw2rSbrGox1Dca6BrNadQ2diElOBP45sPFoW1U9CTzZTe9M8ijwYmAvsK5n9nVdmyRpjEa5ZPOVwLer6rGjDUlekOSEbvpFwAbge1X1OHAoyQXd5wBvBbaNsG5J0hD6uWTzVuB/Ai9J8liSd3Rdm3n6B7gvB77RXcL5eeDdVXX0Q+D3AJ8BdgOP4pU7kjR2y57eqaqLF2m/bIG224HbFxn/AHDOQn2SpPHwG7mS1BBDX5IaYuhLUkMMfUlqiKEvSQ0x9CWpIYa+JDXE0Jekhhj6ktQQQ1+SGmLoS1JDDH1JaoihL0kNMfQlqSGGviQ1xNCXpIYY+pLUEENfkhpi6EtSQwx9SWrIsqGf5IYk+5M81NP24SR7kzzY3S7s6bsiye4kjyR5dU/7pq5td5LLV35TJEnL6edI/0Zg0wLtn6iq87rbnQBJzgI2A2d38/xJkhOSnAD8MfAa4Czg4m6sJGmMTlxuQFXdl2R9n8u7CJitqieB7yfZDZzf9e2uqu8BJJntxn5z4IolSUNLVS0/aD7076iqc7rHHwYuAw4BDwAfqKonklwL3F9Vn+3GXQ/c1S1mU1W9s2t/C/CyqnrfIuvbAmwBmJyc3Dg7OzvUxu0/cJB9h4eadSTnnn7ykv1zc3NMTEyMqZr+WddgrGsw1jWYUeqamZnZWVVTC/Ute6S/iOuAjwLV3V8NvH3IZT1NVW0FtgJMTU3V9PT0UMu55pZtXL1r2E0c3p5Lppfs37FjB8Nu02qyrsFY12CsazCrVddQiVhV+45OJ/k0cEf3cC9wRs/QdV0bS7RLksZkqEs2k5zW8/CNwNEre7YDm5M8J8mZwAbgq8DXgA1JzkzybOY/7N0+fNmSpGEse6Sf5FZgGjg1yWPAh4DpJOcxf3pnD/AugKp6OMltzH9AewR4b1U91S3nfcCXgBOAG6rq4RXfGknSkvq5eufiBZqvX2L8lcCVC7TfCdw5UHWSpBXlN3IlqSGGviQ1xNCXpIYY+pLUEENfkhpi6EtSQwx9SWqIoS9JDTH0Jakhhr4kNcTQl6SGGPqS1BBDX5IaYuhLUkMMfUlqiKEvSQ0x9CWpIYa+JDXE0Jekhiwb+kluSLI/yUM9bf85ybeTfCPJF5Kc0rWvT3I4yYPd7VM982xMsivJ7iSfTJLV2SRJ0mL6OdK/Edh0TNvdwDlV9RvAd4Arevoerarzutu7e9qvA34X2NDdjl2mJGmVLRv6VXUfcOCYtv9RVUe6h/cD65ZaRpLTgF+pqvurqoCbgTcMV7IkaViZz+BlBiXrgTuq6pwF+v4c+FxVfbYb9zDzR/+HgD+qqr9OMgVcVVWv7Ob5beCDVfW6Rda3BdgCMDk5uXF2dnbwLQP2HzjIvsNDzTqSc08/ecn+ubk5JiYmxlRN/6xrMNY1GOsazCh1zczM7KyqqYX6ThylqCT/FjgC3NI1PQ68sKp+mGQj8MUkZw+63KraCmwFmJqaqunp6aHqu+aWbVy9a6RNHMqeS6aX7N+xYwfDbtNqsq7BWNdgrGswq1XX0ImY5DLgdcArulM2VNWTwJPd9M4kjwIvBvby86eA1nVtkqQxGuqSzSSbgD8AXl9VP+lpf0GSE7rpFzH/ge33qupx4FCSC7qrdt4KbBu5eknSQJY90k9yKzANnJrkMeBDzF+t8xzg7u7Ky/u7K3VeDnwkyf8Dfgq8u6qOfgj8HuavBHoucFd3kySN0bKhX1UXL9B8/SJjbwduX6TvAeBpHwRLksbHb+RKUkMMfUlqiKEvSQ0x9CWpIYa+JDXE0Jekhhj6ktQQQ1+SGmLoS1JDDH1JaoihL0kNMfQlqSGGviQ1xNCXpIYY+pLUEENfkhpi6EtSQwx9SWqIoS9JDTH0JakhfYV+khuS7E/yUE/brya5O8l3u/vnd+1J8skku5N8I8lLe+a5tBv/3SSXrvzmSJKW0u+R/o3ApmPaLgfuqaoNwD3dY4DXABu62xbgOpj/IwF8CHgZcD7woaN/KCRJ49FX6FfVfcCBY5ovAm7qpm8C3tDTfnPNux84JclpwKuBu6vqQFU9AdzN0/+QSJJWUaqqv4HJeuCOqjqne/yjqjqlmw7wRFWdkuQO4Kqq+nLXdw/wQWAa+OWq+o9d+78DDlfVxxZY1xbm3yUwOTm5cXZ2dqiN23/gIPsODzXrSM49/eQl++fm5piYmBhTNf2zrsH4/BqMdQ1mlLpmZmZ2VtXUQn0njlRVp6oqSX9/Pfpb3lZgK8DU1FRNT08PtZxrbtnG1btWZBMHsueS6SX7d+zYwbDbtJqsazA+vwZjXYNZrbpGuXpnX3fahu5+f9e+FzijZ9y6rm2xdknSmIwS+tuBo1fgXAps62l/a3cVzwXAwap6HPgS8Kokz+8+wH1V1yZJGpO+3psmuZX5c/KnJnmM+atwrgJuS/IO4AfAm7vhdwIXAruBnwBvA6iqA0k+CnytG/eRqjr2w2FJ0irqK/Sr6uJFul6xwNgC3rvIcm4Abui7OknSivIbuZLUEENfkhpi6EtSQwx9SWqIoS9JDTH0Jakhhr4kNcTQl6SGGPqS1BBDX5IaYuhLUkMMfUlqiKEvSQ0x9CWpIYa+JDXE0Jekhhj6ktQQQ1+SGmLoS1JDDH1JasjQoZ/kJUke7LkdSvL+JB9Osren/cKeea5IsjvJI0levTKbIEnq14nDzlhVjwDnASQ5AdgLfAF4G/CJqvpY7/gkZwGbgbOBXwf+MsmLq+qpYWuQJA1mpU7vvAJ4tKp+sMSYi4DZqnqyqr4P7AbOX6H1S5L6kKoafSHJDcDXq+raJB8GLgMOAQ8AH6iqJ5JcC9xfVZ/t5rkeuKuqPr/A8rYAWwAmJyc3zs7ODlXX/gMH2Xd4qFlHcu7pJy/ZPzc3x8TExJiq6Z91Dcbn12CsazCj1DUzM7OzqqYW6hv69M5RSZ4NvB64omu6DvgoUN391cDbB1lmVW0FtgJMTU3V9PT0ULVdc8s2rt418iYObM8l00v279ixg2G3aTVZ12B8fg3GugazWnWtxOmd1zB/lL8PoKr2VdVTVfVT4NP87BTOXuCMnvnWdW2SpDFZidC/GLj16IMkp/X0vRF4qJveDmxO8pwkZwIbgK+uwPolSX0a6b1pkpOA3wHe1dP8n5Kcx/zpnT1H+6rq4SS3Ad8EjgDv9codSRqvkUK/qn4M/NoxbW9ZYvyVwJWjrFOSNDy/kStJDTH0Jakhhr4kNcTQl6SGGPqS1BBDX5IaYuhLUkMMfUlqiKEvSQ0x9CWpIYa+JDXE0Jekhhj6ktQQQ1+SGmLoS1JDDH1JaoihL0kNMfQlqSGGviQ1ZOTQT7Inya4kDyZ5oGv71SR3J/lud//8rj1JPplkd5JvJHnpqOuXJPVvpY70Z6rqvKqa6h5fDtxTVRuAe7rHAK8BNnS3LcB1K7R+SVIfVuv0zkXATd30TcAbetpvrnn3A6ckOW2VapAkHSNVNdoCku8DTwAF/Neq2prkR1V1Stcf4ImqOiXJHcBVVfXlru8e4INV9cAxy9zC/DsBJicnN87Ozg5V2/4DB9l3eNgtG965p5+8ZP/c3BwTExNjqqZ/1jUYn1+Dsa7BjFLXzMzMzp4zLz/nxJGqmvdPq2pvkn8A3J3k272dVVVJBvrLUlVbga0AU1NTNT09PVRh19yyjat3rcQmDmbPJdNL9u/YsYNht2k1WddgfH4NxroGs1p1jXx6p6r2dvf7gS8A5wP7jp626e73d8P3Amf0zL6ua5MkjcFIoZ/kpCTPOzoNvAp4CNgOXNoNuxTY1k1vB97aXcVzAXCwqh4fpQZJUv9GfW86CXxh/rQ9JwJ/WlX/PcnXgNuSvAP4AfDmbvydwIXAbuAnwNtGXL8kaQAjhX5VfQ/4zQXafwi8YoH2At47yjolScPzG7mS1BBDX5IaYuhLUkMMfUlqiKEvSQ0x9CWpIYa+JDXE0Jekhhj6ktSQ8f9EoFbV+sv/Yuh5P3DuES4bcv49V7126PVKGh+P9CWpIYa+JDXE0Jekhhj6ktQQQ1+SGmLoS1JDDH1JaoihL0kN8ctZkrSEUb7wOIobN520Ksv1SF+SGjJ06Cc5I8m9Sb6Z5OEkv9e1fzjJ3iQPdrcLe+a5IsnuJI8kefVKbIAkqX+jnN45Anygqr6e5HnAziR3d32fqKqP9Q5OchawGTgb+HXgL5O8uKqeGqEGSdIAhj7Sr6rHq+rr3fTfAd8CTl9ilouA2ap6sqq+D+wGzh92/ZKkwaWqRl9Ish64DzgH+H3gMuAQ8ADz7waeSHItcH9Vfbab53rgrqr6/ALL2wJsAZicnNw4Ozs7VF37Dxxk3+GhZh3JuaefvGT/3NwcExMTq7LuXXsPDj3v5HMZen8tt82jWM39NYoWn1+j+EWta5TX1CjOPPmEoffXzMzMzqqaWqhv5Kt3kkwAtwPvr6pDSa4DPgpUd3818PZBlllVW4GtAFNTUzU9PT1Ubdfcso2rd43/AqU9l0wv2b9jxw6G3ablDPvTyDD/08rD7q/ltnkUq7m/RtHi82sUv6h1jfKaGsWNm05alf010tU7SZ7FfODfUlV/BlBV+6rqqar6KfBpfnYKZy9wRs/s67o2SdKYjHL1ToDrgW9V1cd72k/rGfZG4KFuejuwOclzkpwJbAC+Ouz6JUmDG+W96W8BbwF2JXmwa/tD4OIk5zF/emcP8C6Aqno4yW3AN5m/8ue9XrkjSeM1dOhX1ZeBLNB15xLzXAlcOew6JUmj8Ru5ktQQf3tHUt9G+R2aD5x7ZOgrYfZc9dqh16uf55G+JDXE0Jekhhj6ktQQQ1+SGmLoS1JDDH1JaoihL0kNMfQlqSGGviQ1xNCXpIYY+pLUEENfkhpi6EtSQwx9SWqIoS9JDTH0Jakhhr4kNcTQl6SGjD30k2xK8kiS3UkuH/f6JallYw39JCcAfwy8BjgLuDjJWeOsQZJaNu4j/fOB3VX1var6v8AscNGYa5CkZqWqxrey5E3Apqp6Z/f4LcDLqup9x4zbAmzpHr4EeGTIVZ4K/O2Q864m6xqMdQ3GugbzTKzrH1XVCxbqOHH4elZPVW0Fto66nCQPVNXUCpS0oqxrMNY1GOsaTGt1jfv0zl7gjJ7H67o2SdIYjDv0vwZsSHJmkmcDm4HtY65Bkpo11tM7VXUkyfuALwEnADdU1cOruMqRTxGtEusajHUNxroG01RdY/0gV5K0tvxGriQ1xNCXpIY8I0J/uZ92SPKcJJ/r+r+SZP1xUtdlSf5Pkge72zvHUNMNSfYneWiR/iT5ZFfzN5K8dLVr6rOu6SQHe/bVvx9TXWckuTfJN5M8nOT3Fhgz9n3WZ11j32dJfjnJV5P8TVfXf1hgzNhfj33WNfbXY8+6T0jyv5LcsUDfyu6vqvqFvjH/gfCjwIuAZwN/A5x1zJj3AJ/qpjcDnztO6roMuHbM++vlwEuBhxbpvxC4CwhwAfCV46SuaeCONXh+nQa8tJt+HvCdBf4dx77P+qxr7Pus2wcT3fSzgK8AFxwzZi1ej/3UNfbXY8+6fx/404X+vVZ6fz0TjvT7+WmHi4CbuunPA69IkuOgrrGrqvuAA0sMuQi4uebdD5yS5LTjoK41UVWPV9XXu+m/A74FnH7MsLHvsz7rGrtuH8x1D5/V3Y69WmTsr8c+61oTSdYBrwU+s8iQFd1fz4TQPx343z2PH+PpT/6/H1NVR4CDwK8dB3UB/IvulMDnk5yxQP+49Vv3Wvgn3dvzu5KcPe6Vd2+r/zHzR4m91nSfLVEXrME+605VPAjsB+6uqkX31xhfj/3UBWvzevwvwB8AP12kf0X31zMh9H+R/Tmwvqp+A7ibn/0119N9nfnfE/lN4Brgi+NceZIJ4Hbg/VV1aJzrXsoyda3JPquqp6rqPOa/cX9+knPGsd7l9FHX2F+PSV4H7K+qnau9rqOeCaHfz087/P2YJCcCJwM/XOu6quqHVfVk9/AzwMZVrqkfx+VPZVTVoaNvz6vqTuBZSU4dx7qTPIv5YL2lqv5sgSFrss+Wq2st91m3zh8B9wKbjulai9fjsnWt0evxt4DXJ9nD/Cngf5bks8eMWdH99UwI/X5+2mE7cGk3/Sbgr6r7VGQt6zrmvO/rmT8vu9a2A2/trki5ADhYVY+vdVFJ/uHR85hJzmf+ubvqQdGt83rgW1X18UWGjX2f9VPXWuyzJC9Icko3/Vzgd4BvHzNs7K/Hfupai9djVV1RVeuqaj3zGfFXVfWvjhm2ovvruPyVzUHUIj/tkOQjwANVtZ35F8d/S7Kb+Q8LNx8ndf2bJK8HjnR1XbbadSW5lfmrOk5N8hjwIeY/1KKqPgXcyfzVKLuBnwBvW+2a+qzrTcC/TnIEOAxsHsMfbpg/EnsLsKs7Hwzwh8ALe2pbi33WT11rsc9OA27K/H+Y9EvAbVV1x1q/Hvusa+yvx8Ws5v7yZxgkqSHPhNM7kqQ+GfqS1BBDX5IaYuhLUkMMfUlqiKEvSQ0x9CWpIf8fosmZRtRlzjQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df['diagnosis'].hist()\n",
    "train_df['diagnosis'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_valid= train_test_split(train_df,\n",
    "                                  stratify = train_df['diagnosis'],\n",
    "                                  test_size = 0.20,\n",
    "                                random_state = 2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1444\n",
       "2     799\n",
       "1     296\n",
       "4     236\n",
       "3     154\n",
       "Name: diagnosis, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_train['diagnosis'].hist()\n",
    "x_train['diagnosis'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subtract_median_bg_image(im):\n",
    "    k = np.max(im.shape)//20*2+1\n",
    "    bg = cv2.medianBlur(im, k)\n",
    "    return cv2.addWeighted (im, 4, bg, -4, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image_path, desired_size=256):\n",
    "    im = Image.open(image_path) \n",
    "    im = im.resize((desired_size, )*2, resample=Image.LANCZOS)\n",
    "    \n",
    "    return im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1444/1444 [02:02<00:00, 11.79it/s]\n"
     ]
    }
   ],
   "source": [
    "x_0 = np.empty((len(x_train[x_train['diagnosis'] == 0]), 256, 256, 3), dtype=np.uint8)\n",
    "\n",
    "for i, image_id in enumerate(tqdm(x_train[x_train['diagnosis'] == 0]['id_code'])):\n",
    "    x_0[i, :, :, :] = preprocess_image(\n",
    "        f'train_images/{image_id}.png'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('x0',x_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 296/296 [00:51<00:00,  5.55it/s]\n"
     ]
    }
   ],
   "source": [
    "x_1 = np.empty((len(x_train[x_train['diagnosis'] == 1]), 256, 256, 3), dtype=np.uint8)\n",
    "\n",
    "for i, image_id in enumerate(tqdm(x_train[x_train['diagnosis'] == 1]['id_code'])):\n",
    "    x_1[i, :, :, :] = preprocess_image(\n",
    "        f'train_images/{image_id}.png'\n",
    "    )\n",
    "np.save('x1',x_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 799/799 [02:35<00:00,  4.57it/s]\n"
     ]
    }
   ],
   "source": [
    "x_2 = np.empty((len(x_train[x_train['diagnosis'] == 2]), 256, 256, 3), dtype=np.uint8)\n",
    "\n",
    "for i, image_id in enumerate(tqdm(x_train[x_train['diagnosis'] == 2]['id_code'])):\n",
    "    x_2[i, :, :, :] = preprocess_image(\n",
    "        f'train_images/{image_id}.png'\n",
    "    )\n",
    "np.save('x2',x_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 154/154 [00:29<00:00,  4.81it/s]\n"
     ]
    }
   ],
   "source": [
    "x_3 = np.empty((len(x_train[x_train['diagnosis'] == 3]), 256, 256, 3), dtype=np.uint8)\n",
    "\n",
    "for i, image_id in enumerate(tqdm(x_train[x_train['diagnosis'] == 3]['id_code'])):\n",
    "    x_3[i, :, :, :] = preprocess_image(\n",
    "        f'train_images/{image_id}.png'\n",
    "    )\n",
    "np.save('x3',x_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 236/236 [00:46<00:00,  5.39it/s]\n"
     ]
    }
   ],
   "source": [
    "x_4 = np.empty((len(x_train[x_train['diagnosis'] == 4]), 256, 256, 3), dtype=np.uint8)\n",
    "\n",
    "for i, image_id in enumerate(tqdm(x_train[x_train['diagnosis'] == 4]['id_code'])):\n",
    "    x_4[i, :, :, :] = preprocess_image(\n",
    "        f'train_images/{image_id}.png'\n",
    "    )\n",
    "np.save('x4',x_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_1 = np.load('x1.npy')\n",
    "# x_2 = np.load('x2.npy')\n",
    "# x_3 = np.load('x3.npy')\n",
    "# x_4 = np.load('x4.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_0 = np.expand_dims(x_train[x_train['diagnosis'] == 0]['diagnosis'],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((296, 1), (799, 1), (154, 1), (236, 1))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_1 = np.expand_dims(x_train[x_train['diagnosis'] == 1]['diagnosis'],1)\n",
    "y_2 = np.expand_dims(x_train[x_train['diagnosis'] == 2]['diagnosis'],1)\n",
    "y_3 = np.expand_dims(x_train[x_train['diagnosis'] == 3]['diagnosis'],1)\n",
    "y_4 = np.expand_dims(x_train[x_train['diagnosis'] == 4]['diagnosis'],1)\n",
    "y_1.shape,y_2.shape,y_3.shape,y_4.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**-----------------------Oversampling SMOTE------------------------------------**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1095, 256, 256, 3), (1095, 1))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_1_2 = np.vstack((x_1,x_2))\n",
    "y_1_2 = np.vstack((y_1,y_2))\n",
    "x_1_2.shape,y_1_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "smote = SMOTE(ratio='minority')\n",
    "X_sm_1_2, y_sm_1_2 = smote.fit_sample(x_1_2.reshape((len(x_1_2),-1)), y_1_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('X_sm_1_2',X_sm_1_2)\n",
    "np.save('y_sm_1_2',y_sm_1_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((953, 256, 256, 3), (953, 1))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_3_2 = np.vstack((x_3,x_2))\n",
    "y_3_2 = np.vstack((y_3,y_2))\n",
    "x_3_2.shape,y_3_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sm_3_2, y_sm_3_2 = smote.fit_sample(x_3_2.reshape((len(x_3_2),-1)), y_3_2)\n",
    "np.save('X_sm_3_2',X_sm_3_2)\n",
    "np.save('y_sm_3_2',y_sm_3_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_4_2 = np.vstack((x_4,x_2))\n",
    "y_4_2 = np.vstack((y_4,y_2))\n",
    "x_4_2.shape,y_4_2.shape\n",
    "X_sm_4_2, y_sm_4_2 = smote.fit_sample(x_4_2.reshape((len(x_4_2),-1)), y_4_2)\n",
    "np.save('X_sm_4_2',X_sm_4_2)\n",
    "np.save('y_sm_4_2',y_sm_4_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_sm_1_2 = np.expand_dims(y_sm_1_2,1)\n",
    "y_sm_3_2 = np.expand_dims(y_sm_3_2,1)\n",
    "y_sm_4_2 = np.expand_dims(y_sm_4_2,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6238, 1)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = np.vstack((y_0,y_sm_1_2,y_sm_3_2,y_sm_4_2))\n",
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1444.,    0.,  799.,    0.,    0., 2397.,    0.,  799.,    0.,\n",
       "         799.]),\n",
       " array([0. , 0.4, 0.8, 1.2, 1.6, 2. , 2.4, 2.8, 3.2, 3.6, 4. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sm_1_2 = X_sm_1_2.reshape((-1,256,256,3))\n",
    "X_sm_3_2 = X_sm_3_2.reshape((-1,256,256,3))\n",
    "X_sm_4_2 = X_sm_4_2.reshape((-1,256,256,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6238, 256, 256, 3)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tr = np.vstack((x_0,X_sm_1_2,X_sm_3_2,X_sm_4_2))\n",
    "X_tr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# N = test_df.shape[0]\n",
    "# x_test = np.empty((N, 224, 224, 3), dtype=np.uint8)\n",
    "\n",
    "# for i, image_id in enumerate(tqdm(test_df['id_code'])):\n",
    "#     x_test[i, :, :, :] = preprocess_image(\n",
    "#         f'test_images/{image_id}.png'\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6238, 256, 256, 3)\n",
      "(6238, 5)\n"
     ]
    }
   ],
   "source": [
    "y_train = pd.get_dummies(np.squeeze(labels)).values\n",
    "\n",
    "print(X_tr.shape)\n",
    "print(y_train.shape)\n",
    "# print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original y_train: [1444  799 2397  799  799]\n",
      "Multilabel version: [6238 4794 3995 1598  799]\n"
     ]
    }
   ],
   "source": [
    "y_train_multi = np.empty(y_train.shape, dtype=y_train.dtype)\n",
    "y_train_multi[:, 4] = y_train[:, 4]\n",
    "\n",
    "for i in range(3, -1, -1):\n",
    "    y_train_multi[:, i] = np.logical_or(y_train[:, i], y_train_multi[:, i+1])\n",
    "\n",
    "print(\"Original y_train:\", y_train.sum(axis=0))\n",
    "print(\"Multilabel version:\", y_train_multi.sum(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(\n",
    "    X_tr, y_train_multi, \n",
    "    test_size=0.15, \n",
    "    random_state=2019\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "del X_sm_1_2,X_sm_3_2,X_sm_4_2,y_sm_1_2,y_sm_3_2,y_sm_4_2,x_0,x_1,x_2,x_3,x_4,y_0,y_1,y_2,y_3,y_4,x_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('x_train',x_train)\n",
    "np.save('x_val',x_val)\n",
    "np.save('y_train',y_train)\n",
    "np.save('y_val',y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**-------------------------------------- Load saved image --------------------------**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.load('x_train.npy')\n",
    "x_val = np.load('x_val.npy')\n",
    "y_train = np.load('y_train.npy')\n",
    "y_val = np.load('y_val.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5302, 256, 256, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**---------------------------- DO Subtract median bg image -----------------------**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5302/5302 [00:25<00:00, 208.13it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(5302, 256, 256, 3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in tqdm(range(len(x_train))):\n",
    "    x_train[i] = subtract_median_bg_image(x_train[i])\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 936/936 [00:04<00:00, 210.04it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(936, 256, 256, 3)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in tqdm(range(len(x_val))):\n",
    "    x_val[i] = subtract_median_bg_image(x_val[i])\n",
    "x_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "\n",
    "def create_datagen():\n",
    "    return ImageDataGenerator(\n",
    "        zoom_range=0.15,  # set range for random zoom\n",
    "        # set mode for filling points outside the input boundaries\n",
    "        fill_mode='constant',\n",
    "        cval=0.,  # value used for fill_mode = \"constant\"\n",
    "        horizontal_flip=True,  # randomly flip images\n",
    "        vertical_flip=True,  # randomly flip images\n",
    "    )\n",
    "\n",
    "# Using original generator\n",
    "data_generator = create_datagen().flow(x_train, y_train, batch_size=BATCH_SIZE, seed=2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Metrics(Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.val_kappas = []\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        X_val, y_val = self.validation_data[:2]\n",
    "        y_val = y_val.sum(axis=1) - 1\n",
    "        \n",
    "        y_pred = self.model.predict(X_val) > 0.5\n",
    "        y_pred = y_pred.astype(int).sum(axis=1) - 1\n",
    "\n",
    "        _val_kappa = cohen_kappa_score(\n",
    "            y_val,\n",
    "            y_pred, \n",
    "            weights='quadratic'\n",
    "        )\n",
    "\n",
    "        self.val_kappas.append(_val_kappa)\n",
    "\n",
    "        print(f\"val_kappa: {_val_kappa:.4f}\")\n",
    "        \n",
    "        if _val_kappa == max(self.val_kappas):\n",
    "            print(\"Validation Kappa has improved. Saving model.\")\n",
    "            self.model.save('model_256_os_sm_retina_best.h5')\n",
    "\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "You are trying to load a weight file containing 9 layers into a model with 241 layers.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-c0c2341a9385>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'retina_weights.best.hdf5'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0minclude_top\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m )\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/applications/__init__.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'models'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'utils'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mbase_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/applications/densenet.py\u001b[0m in \u001b[0;36mDenseNet121\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mkeras_modules_injection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mDenseNet121\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mdensenet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDenseNet121\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras_applications/densenet.py\u001b[0m in \u001b[0;36mDenseNet121\u001b[0;34m(include_top, weights, input_tensor, input_shape, pooling, classes, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0minput_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                     \u001b[0mpooling\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 311\u001b[0;31m                     **kwargs)\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras_applications/densenet.py\u001b[0m in \u001b[0;36mDenseNet\u001b[0;34m(blocks, include_top, weights, input_tensor, input_shape, pooling, classes, **kwargs)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mweights\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/network.py\u001b[0m in \u001b[0;36mload_weights\u001b[0;34m(self, filepath, by_name, skip_mismatch, reshape)\u001b[0m\n\u001b[1;32m   1164\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1165\u001b[0m                 saving.load_weights_from_hdf5_group(\n\u001b[0;32m-> 1166\u001b[0;31m                     f, self.layers, reshape=reshape)\n\u001b[0m\u001b[1;32m   1167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1168\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_updated_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py\u001b[0m in \u001b[0;36mload_weights_from_hdf5_group\u001b[0;34m(f, layers, reshape)\u001b[0m\n\u001b[1;32m   1028\u001b[0m                          \u001b[0;34m'containing '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1029\u001b[0m                          \u001b[0;34m' layers into a model with '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1030\u001b[0;31m                          str(len(filtered_layers)) + ' layers.')\n\u001b[0m\u001b[1;32m   1031\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1032\u001b[0m     \u001b[0;31m# We batch weight value assignments in a single backend call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: You are trying to load a weight file containing 9 layers into a model with 241 layers."
     ]
    }
   ],
   "source": [
    "densenet = DenseNet121(\n",
    "    weights='retina_weights.best.hdf5',\n",
    "    include_top=False,\n",
    "    input_shape=(256,256,3)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for layer in densenet.layers[:-5]:\n",
    "#     layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    model = Sequential()\n",
    "    model.add(densenet)\n",
    "    model.add(layers.GlobalAveragePooling2D())\n",
    "#     model.add(layers.Dense(256,activation = 'relu'))\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    model.add(layers.Dense(5, activation='sigmoid'))\n",
    "    \n",
    "    model.compile(\n",
    "        loss='binary_crossentropy',\n",
    "        optimizer=Adam(lr=0.00005),\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "densenet121 (Model)          (None, 8, 8, 1024)        7037504   \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 5125      \n",
      "=================================================================\n",
      "Total params: 7,042,629\n",
      "Trainable params: 44,037\n",
      "Non-trainable params: 6,998,592\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/15\n",
      "332/331 [==============================] - 75s 226ms/step - loss: 0.6039 - acc: 0.7113 - val_loss: 1.2809 - val_acc: 0.6241\n",
      "val_kappa: -0.3725\n",
      "Validation Kappa has improved. Saving model.\n",
      "Epoch 2/15\n",
      "332/331 [==============================] - 61s 184ms/step - loss: 0.4367 - acc: 0.8088 - val_loss: 1.3669 - val_acc: 0.6325\n",
      "val_kappa: -0.3043\n",
      "Validation Kappa has improved. Saving model.\n",
      "Epoch 3/15\n",
      "332/331 [==============================] - 61s 184ms/step - loss: 0.3812 - acc: 0.8333 - val_loss: 1.3868 - val_acc: 0.6526\n",
      "val_kappa: -0.2437\n",
      "Validation Kappa has improved. Saving model.\n",
      "Epoch 4/15\n",
      "332/331 [==============================] - 61s 184ms/step - loss: 0.3512 - acc: 0.8485 - val_loss: 1.4112 - val_acc: 0.6729\n",
      "val_kappa: -0.1793\n",
      "Validation Kappa has improved. Saving model.\n",
      "Epoch 5/15\n",
      "332/331 [==============================] - 61s 184ms/step - loss: 0.3295 - acc: 0.8606 - val_loss: 1.4277 - val_acc: 0.6793\n",
      "val_kappa: -0.1386\n",
      "Validation Kappa has improved. Saving model.\n",
      "Epoch 6/15\n",
      "332/331 [==============================] - 61s 184ms/step - loss: 0.3154 - acc: 0.8646 - val_loss: 1.4832 - val_acc: 0.6974\n",
      "val_kappa: -0.0828\n",
      "Validation Kappa has improved. Saving model.\n",
      "Epoch 7/15\n",
      "332/331 [==============================] - 61s 184ms/step - loss: 0.3035 - acc: 0.8702 - val_loss: 1.4061 - val_acc: 0.6944\n",
      "val_kappa: -0.0920\n",
      "Epoch 8/15\n",
      "332/331 [==============================] - 62s 186ms/step - loss: 0.2922 - acc: 0.8772 - val_loss: 1.5033 - val_acc: 0.7094\n",
      "val_kappa: -0.0551\n",
      "Validation Kappa has improved. Saving model.\n",
      "Epoch 9/15\n",
      "332/331 [==============================] - 61s 184ms/step - loss: 0.2863 - acc: 0.8800 - val_loss: 1.4828 - val_acc: 0.7139\n",
      "val_kappa: -0.0383\n",
      "Validation Kappa has improved. Saving model.\n",
      "Epoch 10/15\n",
      "332/331 [==============================] - 62s 185ms/step - loss: 0.2793 - acc: 0.8826 - val_loss: 1.4722 - val_acc: 0.7226\n",
      "val_kappa: -0.0478\n",
      "Epoch 11/15\n",
      "332/331 [==============================] - 62s 186ms/step - loss: 0.2738 - acc: 0.8826 - val_loss: 1.4552 - val_acc: 0.7222\n",
      "val_kappa: -0.0296\n",
      "Validation Kappa has improved. Saving model.\n",
      "Epoch 12/15\n",
      "332/331 [==============================] - 61s 184ms/step - loss: 0.2660 - acc: 0.8879 - val_loss: 1.4556 - val_acc: 0.7299\n",
      "val_kappa: -0.0349\n",
      "Epoch 13/15\n",
      "332/331 [==============================] - 61s 185ms/step - loss: 0.2631 - acc: 0.8877 - val_loss: 1.6147 - val_acc: 0.7188\n",
      "val_kappa: 0.0087\n",
      "Validation Kappa has improved. Saving model.\n",
      "Epoch 14/15\n",
      " 82/331 [======>.......................] - ETA: 37s - loss: 0.2758 - acc: 0.8828"
     ]
    }
   ],
   "source": [
    "kappa_metrics = Metrics()\n",
    "\n",
    "history = model.fit_generator(\n",
    "    data_generator,\n",
    "    steps_per_epoch=x_train.shape[0] / BATCH_SIZE,\n",
    "    epochs=15,\n",
    "    validation_data=(x_val, y_val),\n",
    "    callbacks=[kappa_metrics]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_test = model.predict(x_test) > 0.5\n",
    "# y_test = y_test.astype(int).sum(axis=1) - 1\n",
    "\n",
    "# test_df['diagnosis'] = y_test\n",
    "# test_df.to_csv('submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
